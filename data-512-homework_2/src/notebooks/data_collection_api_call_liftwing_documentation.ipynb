{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Collection: Wikimedia PageInfo API Call"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The functionality to call the wikimedia API as a runnable script is found in src/libs/ores_api_request.py python file. Ways to call the script from the command line with custom arguments is located in src/libs/run_scripts.sh. The following section of the notebook will walk through the specific steps in the script and explain them in detail."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Processing Command Line Arguments, Reading in Files, and Setting Up Logging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following imports are required for this script: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, urllib, time\n",
    "import pandas as pd\n",
    "import sys\n",
    "import os\n",
    "import logging\n",
    "import datetime\n",
    "import requests\n",
    "sys.path.append(\"../\")\n",
    "from libs.api_key_store import API_KEY_STORE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The call of this script from the command line generally takes the form of: \n",
    "\n",
    "bash\n",
    "```\n",
    "#move into local machine scripts directory\n",
    "cd ${local_machine_scripts_directory}\n",
    "\n",
    "#run liftwing API Call\n",
    "python3 ores_api_request.py ${intermediate_data_directory} ${revid_csv_file_name} ${pol_revid_out_file_name}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Where local machine scripts directory is the /src/libs/ absolute path on a local machine. This script will execute api calls against the Wikimedia page views api and write a csv file of the output.\n",
    "\n",
    "Inputs to this script include: \n",
    "- the local intermediate data directory within which the csv file from the page info API call is located, and the output csv file should be written\n",
    "- the csv file containing the revision ids to get data for using the API \n",
    "- the output file name which should be written\n",
    "\n",
    "Accordingly, the first few lines of the script include the following lines of code, meant to process these command line arguments, assign them to variables, read in necessary files, and set up logging so users of this code can track exactly which request succeed, fail, and how long the script takes to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize Key Store so access tokens will not be exposed\n",
    "api_key_store = API_KEY_STORE(\"enwiki-articlequality\")\n",
    "\n",
    "\n",
    "start = datetime.datetime.now()\n",
    "#set up logging \n",
    "logging.basicConfig(level=logging.INFO, \n",
    "                    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "                    filename=f\"../../logs/ores_api_requests.log\")\n",
    "\n",
    "#assign access and output file path variables \n",
    "data_dir = str(sys.argv[1])\n",
    "csv_file_name = str(sys.argv[2])\n",
    "out_file_name = str(sys.argv[3])\n",
    "\n",
    "out_file = os.path.join(data_dir, out_file_name)\n",
    "csv_file = pd.read_csv(os.path.join(data_dir, csv_file_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Setting Up the API Key Store Object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to ensure user specific access keys and personal details are not exposed in this software, the api key store object is used to house these specific parameters. The api key store is discussed further in depth below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "\n",
    "class API_KEY_STORE():\n",
    "    def __init__(self, model):\n",
    "        #Set Wikimedia API parameters from env vars\n",
    "        self.WIKIMEDIA_ACCESS_TOKEN = str(os.getenv(\"WIKIMEDIA_ACCESS_TOKEN\"))\n",
    "        self.WIKIMEDIA_CLIENT_SECRET = str(os.getenv(\"WIKIMEDIA_CLIENT_SECRET\"))\n",
    "        self.WIKIMEDIA_CLIENT_ID = str(os.getenv(\"WIKIMEDIA_CLIENT_ID\"))\n",
    "        self.WIKIMEDIA_EMAIL_ADDRESS = str(os.getenv(\"WIKIMEDIA_EMAIL_ADDRESS\"))\n",
    "        self.WIKIMEDIA_ORES_ENDPOINT = f\"https://api.wikimedia.org/service/lw/inference/v1/models/{model}:predict\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to correctly initialize the API Key Store Object, several environment variables must be set prior to running the ores api call script. \n",
    "This can be achieved through the following (abstracted) lines of code. my_var represents the variable name to be set, in this case one of WIKIMEDIA_ACCESS_TOKEN, WIKIMEDIA_CLIENT_SECRET, WIKIMEDIA_CLIENT_ID, and WIKIMEDIA_EMAIL_ADDRESS. value represents the user specific parameter from the wikimedia api to be stored."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "!conda env config vars set my_var=value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Setting Constants Required for API Calls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step of this script involves setting constant variables required for the rest of the script. This step is largely replicated from a sample code notebook available in the repo : \"wp_ores_liftwing_example.ipynb.\" More thorough attribution for this code can be found in the README.md in this repo. \n",
    "\n",
    "The constants set in this step include: a template for api request headers, a parameter dictionary for this request template, and a template for the data parameter required for the api call.\n",
    "Additionally, we set an assumed api call latency and set at throttle wait parameter so as to not overwhelm the endpoint with api calls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########\n",
    "#\n",
    "#    CONSTANTS\n",
    "#\n",
    "#    The throttling rate is a function of the Access token that you are granted when you request the token. The constants\n",
    "#    come from dissecting the token and getting the rate limits from the granted token. An example of that is below.\n",
    "#\n",
    "API_LATENCY_ASSUMED = 0.002       # Assuming roughly 2ms latency on the API and network\n",
    "API_THROTTLE_WAIT = ((60.0*60.0)/5000.0)-API_LATENCY_ASSUMED  # The key authorizes 5000 requests per hour\n",
    "\n",
    "#    When making automated requests we should include something that is unique to the person making the request\n",
    "#    This should include an email - your UW email would be good to put in there\n",
    "#    \n",
    "#    Because all LiftWing API requests require some form of authentication, you need to provide your access token\n",
    "#    as part of the header too\n",
    "#\n",
    "REQUEST_HEADER_TEMPLATE = {\n",
    "    'User-Agent': \"<{email_address}>, University of Washington, MSDS DATA 512 - AUTUMN 2024\",\n",
    "    'Content-Type': 'application/json',\n",
    "    'Authorization': \"Bearer {access_token}\"\n",
    "}\n",
    "#\n",
    "#    This is a template for the parameters that we need to supply in the headers of an API request\n",
    "#\n",
    "REQUEST_HEADER_PARAMS_TEMPLATE = {\n",
    "    'email_address' : \"\",         # your email address should go here\n",
    "    'access_token'  : \"\"          # the access token you create will need to go here\n",
    "}\n",
    "\n",
    "#\n",
    "#    This is a template of the data required as a payload when making a scoring request of the ORES model\n",
    "#\n",
    "ORES_REQUEST_DATA_TEMPLATE = {\n",
    "    \"lang\":        \"en\",     # required that its english - we're scoring English Wikipedia revisions\n",
    "    \"rev_id\":      \"\",       # this request requires a revision id\n",
    "    \"features\":    True\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Initialize Functions Required for API Calls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following functions in the script define two major steps, and we will walk through them in detail."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4.1: Modularized API Call"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function is a modularized version of the API Call. \n",
    "This function is also adapted, with some modifications, from the \"wp_ores_liftwing_example.ipynb.\" in the src/notebooks subdirectory in this repo. \n",
    "\n",
    "Inputs to this function are: \n",
    "- the revisionid of the article (dynamic input to the function)\n",
    "- an api key store object (See Step 3)\n",
    "- request data template (See ORES_REQUEST_DATA_TEMPLATE in Step 2)\n",
    "- header template (See REQUEST_HEADER_TEMPLATE in Step 2)\n",
    "- header parameters (See REQUEST_HEADER_PARAMS_TEMPLATE in Step 2)\n",
    "- the wait time to throttle api requests (See API_THROTTLE_WAIT in Step 2)\n",
    "\n",
    "Outputs of this function are:\n",
    "- The original article revision ID\n",
    "- Serialized JSON output of the response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_ores_api_call(article_revid = None,\n",
    "                        api_key_store = None,\n",
    "                        request_data = ORES_REQUEST_DATA_TEMPLATE,\n",
    "                        header_format = REQUEST_HEADER_TEMPLATE,\n",
    "                        header_params = REQUEST_HEADER_PARAMS_TEMPLATE,\n",
    "                        request_wait_timing = API_THROTTLE_WAIT):\n",
    "\n",
    "    #setting parameters based on revid and api key store\n",
    "    request_data['rev_id'] = article_revid\n",
    "    header_params['email_address'] = api_key_store.WIKIMEDIA_EMAIL_ADDRESS\n",
    "    header_params['access_token'] = api_key_store.WIKIMEDIA_ACCESS_TOKEN\n",
    "    #Raise exceptions in cases where required inputs are missing\n",
    "    if not article_revid:\n",
    "        raise Exception(\"Must provide a valid article revision ID\")\n",
    "        logging.info(\"API Call failed: Valid article revision ID not Provided!\")\n",
    "    if not header_params[\"email_address\"]:\n",
    "        raise Exception(\"Must provide valid api key store object. Email Address Not Available.\")\n",
    "        logging.info(\"API Call Failed: Valid API Key Store Object not Provided! Email Address Not Available.\")\n",
    "    if not header_params[\"access_token\"]:\n",
    "        raise Exception(\"Must provide valid api key store object. Access Token Not Available.\")\n",
    "        logging.info(\"API Call Failed: Valid API Key Store Object not Provided! Access Token Not Available.\")\n",
    "    # Create a compliant request header from the template and the supplied parameters\n",
    "    headers = dict()\n",
    "    for key in header_format.keys():\n",
    "        headers[str(key)] = header_format[key].format(**header_params)\n",
    "    #execute the request\n",
    "    try:\n",
    "        #throttling\n",
    "        time.sleep(request_wait_timing)\n",
    "        #run post request to API\n",
    "        response = requests.post(api_key_store.WIKIMEDIA_ORES_ENDPOINT, headers=headers, data=json.dumps(request_data))\n",
    "        #raise for status \n",
    "        response.raise_for_status()\n",
    "        #serialize json and log successful response\n",
    "        json_response = response.json() \n",
    "        logging.info(f\"ORES API Call for Article Revision ID {article_revid} succeeded!\")\n",
    "\n",
    "    except Exception as e:\n",
    "        #log failure and set response to None\n",
    "        logging.info(f\"ORES API Call for Article Revision ID {article_revid} failed with reason: {e}\")\n",
    "        json_response = None \n",
    "\n",
    "    return article_revid, json_response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function operates through the following steps: \n",
    "1. Set parameters for the API call based on inputs to the function. \n",
    "2. Raise errors if required inputs are not present\n",
    "3. Create a request header from the template and parameters. \n",
    "4. Try to make the request with an api throttler to limit requests. This requires a post request with the hidden endpoint, the headers, and data for the request.\n",
    "4. Serialize the response into json format and log a successful call.\n",
    "5. Catch and log errors in the call, set the response to None.\n",
    "6. Return the article revision ID and the response object."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4.2 Parse API Response for Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function parses the API call to extract the prediction field from the json response. \n",
    "\n",
    "Input to this function is: \n",
    "- json of the api response \n",
    "\n",
    "Output of this function is: \n",
    "- the prediction field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_api_response(api_response_json):\n",
    "    #extract scores dictionary\n",
    "    scores_dict = api_response_json['enwiki']['scores']\n",
    "    #extract the key of the scores dictionary\n",
    "    scores_key = list(scores_dict.keys())[0]\n",
    "    #extract prediction field\n",
    "    prediction = scores_dict[scores_key]['articlequality']['score']['prediction']\n",
    "    return prediction "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function operates through the following steps: \n",
    "1. Extract the dictionary of scores from the response json\n",
    "2. Extract the key corresponding to article revision ID from the scores dictionary\n",
    "3. Use the key to extract the article quality prediction\n",
    "4. Return the prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4.3 Main Function to Execute Calls and Extract Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This main function runs api calls against the list of articles\n",
    "\n",
    "Inputs to this function are: \n",
    "- an api key store object (set default. See api_key_store in Step 2)\n",
    "- the csv file (set default. See csv_file in Step 1)\n",
    "- the output file (set default. See out_file in Step 1)\n",
    "\n",
    "This function has no output. It ends with writing the file out to a csv. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(api_key_store=api_key_store,\n",
    "            csv_file=csv_file,\n",
    "            out_file=out_file):\n",
    "    #list of revids\n",
    "    revids = csv_file.revision_id.tolist()\n",
    "    #init response list \n",
    "    responses = []\n",
    "    for revision_id in revids:\n",
    "        #append responses for made call\n",
    "        responses.append(make_ores_api_call(article_revid = int(revision_id),\n",
    "                                            api_key_store= api_key_store))\n",
    "    #assign title as keys and items of json obj\n",
    "    formatted_response_list = []\n",
    "    #failure case counter \n",
    "    response_failed_count = 0\n",
    "    #loop through responses, and add dataframe if response is valid\n",
    "    for response in responses:\n",
    "         article_revision_id, json_response = response\n",
    "         if json_response:\n",
    "            prediction = parse_api_response(json_response)\n",
    "            formatted_response_list.append(pd.DataFrame({\"revision_id\" : [article_revision_id],\n",
    "                                                         \"article_quality\" : [prediction]}))\n",
    "         else:\n",
    "            response_failed_count += 1\n",
    "    #concat formatted dataframes and write to out file\n",
    "    response_dataframe = pd.concat(formatted_response_list)\n",
    "    response_dataframe.to_csv(out_file)\n",
    "    #logging of total time and api calls failed\n",
    "    end = datetime.datetime.now()\n",
    "    logging.info(f\"This run took {end - start} seconds to complete!\")\n",
    "    logging.info(f\"{response_failed_count} api calls failed.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function operates through the following steps: \n",
    "1. Create a list of revision ids from the csv file.\n",
    "2. Loop through those revision ids and append to a responses list.\n",
    "3. Loop through the response list and format a dataframe per response by extracting the prediction.\n",
    "4. Updating the failure case counter if the response is none.\n",
    "5. Concatenating the dataframes across response and writing to the out file.\n",
    "6. Logging the total time, and how many calls failed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Failure Rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we understand the API call failure rate for the ORES liftwing API across our calls. To do so, we read in our log file and analyze occurences of the failure key word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = []\n",
    "with open(\"../../logs/ores_api_requests.log\", \"r\") as files:\n",
    "    for line in files:\n",
    "        lines.append(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By reviewing the last line, we can identify the number of failed calls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-10-13 17:49:44,841 - INFO - 2 api calls failed.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(lines[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last two lines are not api result logs, so we can subtract them from the length to find the total number of calls. We have logged 2 failed calls, so we can proceed with calculating a rate this way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API Call Failure Rate for liftwing API: 0.028 %\n"
     ]
    }
   ],
   "source": [
    "num_calls = len(lines) - 2\n",
    "print(f\"API Call Failure Rate for liftwing API: {round((2/num_calls) * 100, 3)} %\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
