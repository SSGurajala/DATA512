# DATA 512 Homework 2
## Author : Saisriram Gurajala
## Contact sgura99@uw.edu with any questions and issues

## Goal

The goal of this project is to explore bias in datasets. To that end, the project involves the following steps: constructing, analyzing, and publishing a dataset of article quality scores for wikipedia articles, as generated by the ORES Liftwing model, for a list of politicans from around the world.

## Repository Structure 

This repository has the following structure, generated by the tree command in linux.]
```
data-512-homework_2
├── data
│   ├── final
│   │   ├── wp_countries-no_match.txt
│   │   └── wp_politicians_by_country.csv
│   ├── intermediate
│   │   ├── politicians_by_country_AUG.2024.csv
│   │   ├── politicians_by_revid_article_score_OCT.2024.csv
│   │   ├── politicians_by_revid_OCT.2024.csv
│   │   ├── population_by_country_AUG.2024.csv
│   │   └── population_by_country_region_AUG.2024.csv
├── logs
│   ├── ores_api_requests.log
│   └── pageinfo_api_requests.log
├── src
│   ├── libs
│   │   ├── api_key_store.py
│   │   ├── ores_api_request.py
│   │   ├── page_info_api_request.py
│   │   └── run_scripts.sh
│   ├── notebooks
│   │   ├── data_analysis.ipynb
│   │   ├── data_collection_api_call_liftwing_documentation.ipynb
│   │   ├── data_collection_api_call_pageinfo_documentation.ipynb
│   │   ├── data_wrangling_merge_csvs.ipynb
│   │   ├── data_wrangling_population_by_country.ipynb
│   │   ├── wp_ores_liftwing_example.ipynb
│   │   └── wp_page_info_example.ipynb
├── LICENSE
├── poetry.lock
├── pyproject.toml
└── README.md
```

## Data Source, Documentation, and Licensure

The source data comes from the Wikimedia API, and terms of use for the wikimedia can be found [here](https://foundation.wikimedia.org/wiki/Policy:Terms_of_Use). 

API documentation for the APIs can be found [here](https://api.wikimedia.org/wiki/API_catalog).

This repository contains two pre-made datasets. 

- politicians_by_country_AUG.2024.csv was generated by crawling the [Wikipedia Politicians by Nationality Category](https://en.wikipedia.org/wiki/Category:Politicians_by_nationality) to generate politicians from a range of countries.

- population_by_country_AUG.2024.csv was generated from the Population Reference Bureau's [world population data sheet](https://www.prb.org/international/indicator/population/table)

Portions of the source code were sourced, with modifications, from notebooks created by Dr. David W. McDonald for use in DATA 512 licensed via the [Creative Commons BY](https://creativecommons.org/licenses/by/4.0/). The original, unaltered notebook code is located in the `src/notebooks` directory. 

## Getting Started 

This project, in the interest of reproducibility, manages required packages and package versions using the python poetry package, documentation for which can be found [here](https://python-poetry.org/docs/). More thorough information about using poetry can be found at the link provided, but some brief requirements to use poetry for this project are: 
- some interface for the command line
- python
- the pip utility for installing packages 

Once these requirements are fulfilled, install poetry with pip `pip install poetry`, clone this repo, and run
`poetry install` in the base directory of the repo containing the `pyproject.toml` and `poetry.lock` files. All required packages will be installed into the current environment.

Example commands to run data collection can be found in the `run_scripts.sh` file in the `src/libs` subdirectory in the repo. If you would like to run these commands as is, you will need to set up the bash environment variables `local_machine_scripts_directory`, `intermediate_data_directory`, `revid_csv_file_name`, `pol_revid_out_file_name`, and  `pol_csv_file_name`. These correspond to the scripts and data directory absolute paths in the local machine version of the repo. Additionally, they correspond to the file names you would like toh ave written out for these commands. These scripts must be run in sequence, with `page_info_api_request.py` run before `ores_api_request.py`. These environment variables can be set in your current shell through the command:
`export VARNAME="value"`

## Code Outputs: Intermediate files and Final Outputs

The final outputs of the scripts and notebooks are located in the `/data/final` subdirectory of this repo. These files are as follows: 
- `wp_countries-no_match.txt`: A list of countries which could not be mapped in the file merges occurring in `/src/notebooks/data_wrangling_merge_csvs.ipynb`.
- `wp_politicians_by_country.csv`: The final csv output of the merges occurring in `/src/notebooks/data_wrangling_merge_csvs.ipynb`.

A mix of intermediate files and initially provided files  `/data/intermediate` subdirectory of this repo.

Initial files are: 
- `politicians_by_country_AUG.2024.csv`
- `population_by_country_AUG.2024.csv`

Intermediate files are: 
- `politicians_by_revid_OCT.2024.csv`: output of the `page_info_api_request.py` script. File contains revision ID and article title from each API call.
- `politicians_by_revid_article_score_OCT.2024.csv`: output of the `ores_api_request.py` script. File contains revision ID and article quality score resulting from each API Call.
- `population_by_country_region_AUG.2024.csv`: output of the `data_wrangling_population_by_country.ipynb` notebook. File contains relevant sub region for a given country and population size.

## Notes and Considerations

Some API calls may fail for `ores_api_request.py` script. These are recorded in the logging for this script's run. Additionally, some politicians may have more than one entry for country. This results in duplicates for the page info api call script, which are deduplicated prior to merging in the `/src/notebooks/data_wrangling_merge_csvs.ipynb`.


## Research Implications 

Reflecting on this assignment, I have learned several things about quality scores from the wikimedia API. Specifically, I learned that article count coverage is related to population size from analysis 1. Higher population countries have higher article counts, and largely have higher counts of high quality articles. Regionally, we find that high quality article count is correlated well with article count: regions with higher article coverage tend to have higher count of high quality articles. Interestingly, China has a very low count of high quality articles. I wondered if the sociopolitical situation of countries has some bearing on article qualities, and found indeed that countries located either in hotbed geopolitical regions, such as the middle eastern countries of the "WESTERN ASIA" region, and affluent European countries had higher high quality article counts. 
Conversely, countries in the less geopolitically charged and affluent "OCEANIA" region tend to have lower high quality article counts. 

Before working with data, I imagined the major divide in high quality article count would be western europe and north america versus other countries. I figured this dichotomy would largely be the deciding factor in coverage and high quality article count. In terms of potential sources of bias, I found article coverage was largely aligned with population count: the highest article coverage count country in the bottom 10 was still much lower than the lowest article coverage country in the top 10. Additionally, I noted that affluent countries and countries in geopolitically charged areas tend to have higher article coverage and high quality article counts. This data is fundamentally useful for bridging the gap in article quality and article count for these countries and regions where article coverage and high quality article count is lower. Insights from this data can inform focus for article curation and article quality improvement. In terms of additional supplementation and transformation, researchers may find it useful to report financial metrics such as GDP to understand if relative affluence has an impact on article quality. Adjusting for relative affluence would enable analysis of independent, region specific signals in the data.   




