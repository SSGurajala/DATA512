{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Wrangling: Combining API Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The functionality to combine api results across access modes, as output by the libs/src/api_request.py, is found in libs/src/combine_api_results.py python file. Thorough in line commenting is also available, along with ways to call the script from the command line with custom arguments in libs/src/run_scripts.sh. The following section of the notebook will walk through the specific steps in the script and explain them in detail."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Processing Command Line Arguments, Reading in Files, and Setting Up Logging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dependencies for this script involves importing the following libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import sys \n",
    "from collections import Counter, defaultdict\n",
    "import pandas as pd\n",
    "import os\n",
    "import logging\n",
    "import datetime "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The call of this script from the command line generally takes the form of: \n",
    "\n",
    "bash\n",
    "```\n",
    "#move into scripts directory\n",
    "!cd ${local_machine_scripts_directory}\n",
    "#combine api results for given access modes\n",
    "!python3 combine_api_results.py ${access_mode_1} ${access_mode_2} ${delete_originals} ${output_access} ${local_machine_data_directory} \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Where local machine scripts directory is the /libs/src/ absolute path on a local machine. This script will combine api results for a given article by time stamp, and write an output json of the combined results. \n",
    "\n",
    "Inputs to this script are: \n",
    "- the first access mode to be combined \n",
    "- the second access mode to be combined \n",
    "- a boolean (True or False) of whether the original files should be deleted\n",
    "- the name of the output access mode \n",
    "- the absolute path on a local machine of the data directory in this repo "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accordingly, the first few lines of the script include the following lines of code, meant to process these command line arguments, assign them to variables, and set up logging so users of this code can track exactly which article merge request succeed, fail, and how long the script takes to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = datetime.datetime.now()\n",
    "\n",
    "#assign access and output file path variables \n",
    "access1 = str(sys.argv[1])\n",
    "access2 = str(sys.argv[2])\n",
    "#do we want to delete originals or no\n",
    "delete_originals = bool(sys.argv[3] == \"True\")\n",
    "out_access = str(sys.argv[4])\n",
    "data_dir = str(sys.argv[5])\n",
    "\n",
    "logging.basicConfig(level=logging.INFO, \n",
    "                    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "                    filename=f\"../../logs/combine_api_results_{access1}_{access2}.log\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logging is output to a file \"combine_api_results_{access1}_{access2}.log\" in a directory named logs in the main repo where it is named dynamically based on the access modes to be merged, as specified in the command line call to the python script. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Setting Constants Required for Function Calls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step of this script includes setting the start and end dates, hardcoded from the request template included in the \"wp_article_views_example.ipynb\" notebook. Additionally, the output file path and access json file paths strings are constructed from the variables. The two access jsons are read in into the objects `access1_json` and `access2_json`. For future steps, the records corresponding to a given article from each access json file are merged into a python dictionary named `merged_json`.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#start and end for path strings\n",
    "start = \"2015070100\"\n",
    "end = \"2024093000\"\n",
    "\n",
    "#format output file path\n",
    "out_file_path = f\"{data_dir}/rare-disease_monthly_{out_access}_{start}-{end}.json\"\n",
    "\n",
    "#format json paths\n",
    "access1_json_path = f\"{data_dir}/rare-disease_monthly_{access1}_{start}-{end}.json\"\n",
    "access2_json_path = f\"{data_dir}/rare-disease_monthly_{access2}_{start}-{end}.json\"\n",
    "\n",
    "#load json objects\n",
    "with open(access1_json_path, \"r\") as file:  \n",
    "    access1_json = json.load(file)\n",
    "\n",
    "with open(access2_json_path, \"r\") as file:  \n",
    "    access2_json = json.load(file)\n",
    "\n",
    "#put lists together per key to get all timestamps from both sources in same list\n",
    "merged_json = {}\n",
    "for title in access1_json.keys():\n",
    "    merged_json[title] = access1_json[title] + access2_json[title]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Initialize Functions Required For API Call Result Merging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3.1: Summing Views for a Given Timestamp and Article"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `merged_json` object constructed in step 2 will have duplicated records for a given timestamp in the records corresponding to a given article. This function works to combine views for a given article by timestamp, and output a formatted json object.\n",
    "\n",
    "Input to this function is:\n",
    "-  the merged json object from Step 2\n",
    "\n",
    "Output of this function is: \n",
    "- the merged output dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to sum views for the same articles timestamps\n",
    "def sum_unique_views_output_dict(merged_json_object):\n",
    "    #initalize default dict of lists for output\n",
    "    result_dict = defaultdict(list)\n",
    "    #loop through list of api results (now with two entries per timestamp)\n",
    "    for article, api_result_list in merged_json_object.items():\n",
    "        #initialize default view tracker dictionary per timestamp\n",
    "        view_tracker = defaultdict(lambda : {\n",
    "                'project' : None,\n",
    "                'granularity' : None,\n",
    "                'agent' : None,\n",
    "                'views' : 0,\n",
    "        })\n",
    "        #loop through every item in the list of resutls \n",
    "        for list_iter in api_result_list:\n",
    "            #intialize the timestamp\n",
    "            timestamp = list_iter['timestamp']\n",
    "            #add the views from a given timestamp\n",
    "            view_tracker[timestamp]['views'] += list_iter['views']\n",
    "            #source other info from the iteration of the list if not already set\n",
    "            if view_tracker[timestamp]['agent'] is None:\n",
    "                view_tracker[timestamp]['project'] = list_iter['project']\n",
    "                view_tracker[timestamp]['granularity'] = list_iter['granularity']\n",
    "                view_tracker[timestamp]['agent'] = list_iter['agent']\n",
    "        #add summed monthly entry to high level output dict\n",
    "        for timestamp in view_tracker.keys():\n",
    "            result_dict[article].append({\n",
    "                'project' :  view_tracker[timestamp]['project'],\n",
    "                'article' : article,\n",
    "                'granularity' : view_tracker[timestamp]['granularity'],\n",
    "                'timestamp' : timestamp,\n",
    "                'agent' : view_tracker[timestamp]['agent'],\n",
    "                'views' : view_tracker[timestamp]['views']\n",
    "            })\n",
    "        logging.info(f\"Result merging has finished for article {article}\")\n",
    "    #convert from default dict to dict\n",
    "    return dict(result_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function leverages the defaultdict object from the collections module. \n",
    "\n",
    "It operates through the following steps: \n",
    "1. Intialize a defaultdict object for the final result dictionary\n",
    "2. Loop through the article title and api result list key, value pairs in the merged json object. \n",
    "3. Initialize a viewtracker defaultdict object for each article's timestamp. \n",
    "4. Loop through each api result in the api result list, and add the views for that result's timestamp to the viewtracker record for that timestamp. Each timestamp therefore only has one entry in the viewtracker defaultdict object.\n",
    "5. Add the auxiliary information from the api result to the viewtracker dict if it does not already exist.\n",
    "6. Loop through the timestamp keys of the viewtracker, and append add a dictionary of the information corresponding to this timestamp key to the final result list for the given article.\n",
    "7. Log the result merging for the given article.\n",
    "8. Return a dictionary object of the result dictionary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3.2: Running the Merge Process for a Given Merged Json Object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function uses the sum_unique_values_output_dict() function defined in Step 3.1, and runs the merge operation. \n",
    "\n",
    "The inputs to this function are: \n",
    "- A given merged JSON object\n",
    "- A delete originals flag, corresponding to the script argument (See Step 1)\n",
    "\n",
    "There are no outputs of this function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_merge(merged_json, delete_originals=False):\n",
    "    #run sum_unique_views_output_dict function for the merged json\n",
    "    output_json = sum_unique_views_output_dict(merged_json)\n",
    "    #write output\n",
    "    with open(out_file_path, 'w') as file:\n",
    "        json.dump(output_json, file)\n",
    "    #delete originals if needed\n",
    "    if delete_originals:\n",
    "        os.remove(access1_json_path)\n",
    "        os.remove(access2_json_path)\n",
    "        logging.info(f\"Temp Files {access1_json_path} and {access2_json_path} removed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function operates through the following steps: \n",
    "1. Run the sum_unique_views_output to produce a summed json object for given original merged output.\n",
    "2. Write the output to the output file path set in Step 2.\n",
    "3. Delete originals based on the flag set in Step 1 and log the deletion. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3.3 Main Function to Execute Merge Run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function pieces together all of the previous steps, and places them in a main function which is called at the end of the script. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    run_merge(merged_json,\n",
    "              delete_originals)\n",
    "    end_time = datetime.datetime.now() \n",
    "    logging.info(f\"Total Run took {end_time - start_time} seconds!\")\n",
    "    \n",
    "main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function operates through the following steps:\n",
    "1. Run the merge for the merged json object generated in Step 2 and delete originals flag set in Step 1 from the command line.\n",
    "2. Log the total run time for the script."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
